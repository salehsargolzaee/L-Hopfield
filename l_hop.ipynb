{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdf334e7-4f98-42d2-99a1-2e7971bade72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "07ddbde9-0e0d-4f28-9c6b-36903515fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L_Hopfield:\n",
    "    def __init__(self, L: int, N: int, lamb: float, H: float) -> None:\n",
    "        \"\"\"\n",
    "        Initialize L-hopfield class.\n",
    "        Parameters:\n",
    "        - L (int): The number of Hopfield nets\n",
    "        - N (int): Dimension of memories (as well as each network)\n",
    "        Returns: \n",
    "        - None\n",
    "        \"\"\"\n",
    "        self.L = L\n",
    "        self.K = L # For simplicity, # Memories == # Networks\n",
    "        self.N = N\n",
    "        self.memories = self.rademacher(self.N, self.L) # shape: (N, L)\n",
    "        self.input = np.sign(np.sum(self.memories, axis = 1)) # shape: (N, )\n",
    "        self.h = self.input.copy() # external fields based on the paper\n",
    "        self.states = np.array([self.input for _ in range(self.L)]) # shape: (L, N)\n",
    "\n",
    "        self.lamb = lamb\n",
    "        self.H = H\n",
    "        \n",
    "\n",
    "    def rademacher(self, dimension: int, samples: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generates an array of i.i.d. Rademacher-distributed random variables, where \n",
    "        each entry is independently sampled from {-1, +1} with equal probability.\n",
    "    \n",
    "        Parameters:\n",
    "        - dimension (int): The number of rows (features) in the output matrix.\n",
    "        - samples (int): The number of columns (samples) in the output matrix.\n",
    "    \n",
    "        Returns:\n",
    "        - np.ndarray: A (dimension, samples) array with Rademacher-distributed entries.\n",
    "        \"\"\"\n",
    "        return np.random.choice([-1, 1], size=(dimension, samples))\n",
    "\n",
    "    def mattis_magnetization(self, a: int, mu: int) -> float:\n",
    "        \"\"\"\n",
    "        Calculates Mattis magnetization between state of a_th network and mu_th memory. \n",
    "        In the case of binary Â±1 vectors, Mattis magnetization is exactly the same as cosine similarity\n",
    "        \n",
    "        Parameters:\n",
    "        a (int): Index of targetted network in the range [0, L - 1].\n",
    "        mu (int): Index of targetted memory in the range [0, K - 1].\n",
    "\n",
    "        Returns:\n",
    "        - float: A number between [-1, 1], representing the alignment between two vectors.\n",
    "        \"\"\"\n",
    "        return np.dot(self.states[a], self.memories[:, mu])/self.N\n",
    "\n",
    "    def intra_layer_energy(self) -> float:\n",
    "        \"\"\"\n",
    "        Calculates the intra_layer contribution to energy function.\n",
    "\n",
    "        Returns:\n",
    "        - float: Total intra_layer energy contribution\n",
    "        \"\"\"\n",
    "        \n",
    "        total = 0\n",
    "        for a in range(self.L):\n",
    "            for mu in range(self.K):\n",
    "                total += self.mattis_magnetization(a, mu)**2\n",
    "                \n",
    "        total *= -self.N\n",
    "        \n",
    "        return total\n",
    "\n",
    "    def inter_layer_energy(self, lamb: float) -> float:\n",
    "        \"\"\"\n",
    "        Calculates the inter_layer contribution to energy function.\n",
    "\n",
    "        Parameters:\n",
    "        - lamb (float): Controlling the intensity of the inter-layer interaction strength (lambda in the paper).\n",
    "        \n",
    "        Returns:\n",
    "        - float: Total inter_layer energy contribution\n",
    "        \"\"\"\n",
    "        \n",
    "        total = 0\n",
    "        for a in range(self.L):\n",
    "            for b in range(self.L):\n",
    "                if (a == b):\n",
    "                    continue\n",
    "                for mu in range(self.K):\n",
    "                    total += (self.mattis_magnetization(a, mu) * self.mattis_magnetization(b, mu))**2\n",
    "        total *= lamb*self.N\n",
    "\n",
    "        return total\n",
    "\n",
    "    def external_field_energy(self, H: float) -> float:\n",
    "        \"\"\"\n",
    "        Calculates the external field contribution to energy function.\n",
    "\n",
    "        Parameters:\n",
    "        - H (float): Controlling the intensity of the external field.\n",
    "        \n",
    "        Returns:\n",
    "        - float: Total external field energy contribution\n",
    "        \"\"\"\n",
    "        return -H * np.sum(self.states.dot(self.h))\n",
    "                   \n",
    "\n",
    "    def energy(self) -> float:\n",
    "        \"\"\"\n",
    "        Calculates the total energy function.\n",
    "\n",
    "        Parameters: \n",
    "        - lamb (float): Controlling the intensity of the inter-layer interaction strength (lambda in the paper).\n",
    "        - H (float): Controlling the intensity of the external field.\n",
    "\n",
    "        Returns: \n",
    "        - float: Total energy.\n",
    "        \"\"\"\n",
    "        return self.intra_layer_energy() + self.inter_layer_energy(self.lamb) + self.external_field_energy(self.H)\n",
    "\n",
    "    def update(self, epochs: int) -> None:\n",
    "        \n",
    "        for _ in range(epochs):\n",
    "            for a in range(self.L):\n",
    "                noise = np.atanh(self.rademacher(self.N, 1))\n",
    "                for i in range(self.N):\n",
    "                    h_tilda = 0\n",
    "                    for b in range(self.L):\n",
    "                        h_tilda += (1 if a == b else -self.lamb)* np.sum([self.memories[i, mu] * np.dot(self.states[b], self.memories[:, mu]) for mu in range(self.K)])\n",
    "                    h_tilda *= 1/self.N\n",
    "                    h_tilda += self.H * self.h[i]\n",
    "                    self.states[a][i] = np.sign(h_tilda + 0.2*noise[i][0])\n",
    "                    \n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "dab86f7d-476d-4ee6-9a15-e4595674f1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = L_Hopfield(L = 3, N = 1000, lamb=20, H= 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "1c079413-599b-4828-a485-39f46e262a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(18424.604866559996)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.energy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "8feb1dcd-a3a7-432c-b387-199cd81f3e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[508, 496, 484],\n",
       "       [508, 496, 484],\n",
       "       [508, 496, 484]])"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.states.dot(net.memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "f261bbee-6588-41e0-92c6-655788ec04be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p4/fv5qp61911x80fx4bspznbv00000gn/T/ipykernel_2175/1827597226.py:120: RuntimeWarning: divide by zero encountered in arctanh\n",
      "  noise = np.atanh(self.rademacher(self.N, 1))\n"
     ]
    }
   ],
   "source": [
    "net.update(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "68980d62-bbf5-47bc-b008-efa454b50155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-30.056528640000003)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.energy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "c72be320-f2d3-46da-b735-ea63580b0913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-12,  -4,  28],\n",
       "       [ 30, -66,  14],\n",
       "       [-28,  72, -16]])"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.states.dot(net.memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdafb390-568e-420f-8dff-fe8363cc4b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c2589c-9741-40e1-ae9f-ccf4a0b95e33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
